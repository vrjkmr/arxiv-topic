# ArXiv Topic Modeling

This repository contains the code for a [Latent Dirichlet Allocation (LDA)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) topic model built and trained on the abstracts of ~160,000 ML-related research papers from the [ArXiv.org dataset](https://www.kaggle.com/Cornell-University/arxiv) on Kaggle. 

To illustrate, shown below is an example of the model's ability to predict topics present in the paper ["Why Molière most likely did write his plays"](https://arxiv.org/abs/2001.01595) by Cafiero and Camps (2020).

```
Paper
-----
"Why Molière most likely did write his plays" (Cafiero & Camps, 2020)

Abstract
--------
  As for Shakespeare, a hard-fought debate has emerged about Molière, a
supposedly uneducated actor who, according to some, could not have written the
masterpieces attributed to him. In the past decades, the century-old thesis
according to which Pierre Corneille would be their actual author has become
popular, mostly because of new works in computational linguistics. These
results are reassessed here through state-of-the-art attribution methods. We
study a corpus of comedies in verse by major authors of Molière and
Corneille's time. Analysis of lexicon, rhymes, word forms, affixes,
morphosyntactic sequences, and function words do not give any clue that another
author among the major playwrights of the time would have written the plays
signed under the name Molière.

Predicted topics
----------------
[('Natural language processing', 0.38158375),
 ('Paper-related', 0.298497),
 ('ML-related terms?', 0.091592446)]
```

### Motivation

You know how when reading research papers, the first thing we read is the abstract? The abstract helps us (as humans) get a general sense of what different topics are explored in any given paper. But what if we can train an unsupervised model to automatically "categorize" papers for us?

In this project, my ultimate goal was to build an clustering model that can:

1. Identify salient trends and sub-topics in machine learning research today, and
2. Automatically predict the topic(s) explored in any given paper simply by looking at its abstract.

### Results: Topics

The final model achieved a coherence score of 49.9%. While this score is quite low (an ideal coherence score tends to be around 60-80%), the model was able to detect some interesting topic clusters, a few of which are listed below. Note that while the topic terms were generated by the LDA model, the topic titles themselves are subjective, since they were added by me after looking at the term distribution for each of the topics.

1. **Algorithms and optimization:** "algorithm", "problem", "search", "optimization", "gradient"
2. **Probabilistic modeling and inference:** "distribution", "bayesian", "inference", "process", "variable"
3. **Natural language processing (NLP):** "language", "text", "semantic", "knowledge", "word"
4. **Computer vision:** "image", "object", "detection", "segmentation", "convolution"
5. **Reinforcement learning:** "agent", "policy", "action", "state", "environment"
6. **Deep learning architectures:** "network", "neural", "deep", "architecture", "layer"
7. **Graph theory:** "graph", "structure", "node", "tree", "edge"
8. **Medicine and healthcare applications** "patient", "covid", "causal", "treatment", "population"

### Model inference

```python
from model import TopicModel
from utils import scrape_arxiv_abstract

lda_filepath = "./models/model_001"
dataset_filepath = "./data/dataset.obj"
topic_model = TopicModel(lda_filepath, dataset_filepath)

# Paper: "Future Frame Prediction of a Video Sequence" (Kaur & Das, 2020)
paper_url = "https://arxiv.org/abs/2009.08825"
abstract = scrape_arxiv_abstract(paper_url)
predictions = topic_model.predict(abstract)
print(predictions)

'''
Output
------
[('Paper-related', 0.25155145),
 ('Computer vision', 0.18688545),
 ('ML-related terms?', 0.17415679)]
'''
```
